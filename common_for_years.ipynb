{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MySQLdb as mdb\n",
    "import os\n",
    "import json\n",
    "from stop_words import get_stop_words\n",
    "from nltk import collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath('..')\n",
    "\n",
    "with open(os.path.join(BASE_DIR, '.secure.settings.json')) as secret:\n",
    "    SECRET = json.loads(secret.read())\n",
    "\n",
    "SECRET_KEY = SECRET[\"SECRET_KEY\"]\n",
    "\n",
    "DATABASES = {\n",
    "    'default': {\n",
    "        'ENGINE': 'django.db.backends.mysql',\n",
    "        'TEST_CHARSET': 'UTF8',\n",
    "        'HOST': '',\n",
    "        'PORT': '3306',\n",
    "    }\n",
    "}\n",
    "\n",
    "DATABASES['default']['NAME'] = SECRET['DEV_DATABASES_NAME']\n",
    "DATABASES['default']['USER'] = SECRET['DEV_DATABASES_USER']\n",
    "DATABASES['default']['PASSWORD'] = SECRET['DEV_DATABASES_PASSWORD']\n",
    "\n",
    "USER = DATABASES['default']['USER']\n",
    "PASSWORD = DATABASES['default']['PASSWORD']\n",
    "NAME = DATABASES['default']['NAME']\n",
    "\n",
    "\n",
    "class Database(object):\n",
    "    \"\"\"Класс для общения с базой данных MySQL\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Создать соединение с базой данных.\n",
    "\n",
    "        В параметрах соединения указывается хост, логин, пароль, название базы данных, кодировка.\n",
    "        \"\"\"\n",
    "        self._connection = mdb.connect('', USER, PASSWORD, NAME, charset='utf8')\n",
    "\n",
    "    def commit(self):\n",
    "        self._connection.commit()\n",
    "\n",
    "    def execute(self, q):\n",
    "        \"\"\"Вернуть результат выполнения запроса в виде массива кортежей.\n",
    "\n",
    "        Каждый кортеж - строка базы данных, сформированная по запросу.\n",
    "        \"\"\"\n",
    "        self.cur = self._connection.cursor()  # mdb.cursors.DictCursor\n",
    "        self.cur.execute(q)\n",
    "        res = self.cur.fetchall()\n",
    "        self.cur.close()\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "req1 = 'SELECT id FROM `annotator_document` WHERE subcorpus=\"RULEC\"'\n",
    "\n",
    "db = Database()\n",
    "rulec = tuple(i[0] for i in db.execute(req1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "req1 = 'SELECT filename FROM `annotator_document` WHERE subcorpus=\"RULEC\"'\n",
    "\n",
    "db = Database()\n",
    "file_draft = tuple(i[0] for i in db.execute(req1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "req1 = 'SELECT filename FROM `annotator_document` WHERE subcorpus=\"RULEC\"'\n",
    "\n",
    "db = Database()\n",
    "files = tuple(i[0] for i in db.execute(req1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_draft = list()\n",
    "for f in files:\n",
    "    if 'draft' in f:\n",
    "        file_draft.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drafts = list() # то что надо исключить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in file_draft:\n",
    "    db = Database()\n",
    "    req = 'SELECT id FROM `annotator_document` WHERE subcorpus=\"RULEC\" AND filename=\"' + n + '\"'\n",
    "    drafts.append(tuple(i[0] for i in db.execute(req)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "req1 = 'SELECT title FROM `annotator_document` WHERE subcorpus=\"RULEC\"'\n",
    "\n",
    "db = Database()\n",
    "titles = tuple(i[0] for i in db.execute(req1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "title_drafts = list()\n",
    "\n",
    "for t in titles:\n",
    "    if 'draft' in t:\n",
    "        if 'draft 1' not in t and '1st draft' not in t and 'first draft' not in t:\n",
    "            title_drafts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for n in title_drafts:\n",
    "    db = Database()\n",
    "    req = 'SELECT id FROM `annotator_document` WHERE subcorpus=\"RULEC\" AND title=\"' + n + '\"'\n",
    "    drafts.append(tuple(i[0] for i in db.execute(req)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "req1 = 'SELECT id FROM `annotator_document` WHERE subcorpus=\"RULEC\" AND language_background=\"FL\" AND date1=2012'\n",
    "\n",
    "db = Database()\n",
    "rulec = tuple(i[0] for i in db.execute(req1))\n",
    "\n",
    "fl_end_texts = []\n",
    "for n in rulec:\n",
    "    f = open('fl/end/' + str(n) + '.txt', 'w', encoding='utf-8')\n",
    "    req2 = 'SELECT text FROM `annotator_sentence` WHERE doc_id_id={}'.format(n)\n",
    "    text = ''\n",
    "    for i in db.execute(req2):\n",
    "        text += i[0]\n",
    "    fl_end_texts.append(text)\n",
    "    f.write(text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_to_use = list()\n",
    "for dr in drafts:\n",
    "    for d in dr:\n",
    "        not_to_use.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "    req1 = 'SELECT id FROM `annotator_document` WHERE subcorpus=\"RULEC\"'\n",
    "    db = Database()\n",
    "    rulec = tuple(i[0] for i in db.execute(req1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_texts(bg, year):\n",
    "    req1 = 'SELECT id FROM `annotator_document` WHERE subcorpus=\"RULEC\" AND language_background=\"' + bg + '\" AND date1={}'.format(year)\n",
    "\n",
    "    db = Database()\n",
    "    rulec = tuple(i[0] for i in db.execute(req1))\n",
    "\n",
    "    texts = []\n",
    "    for n in rulec:\n",
    "        if n not in not_to_use:\n",
    "            f = open(bg.lower() + '/' + str(year) + '/' + str(n) + '.txt', 'w', encoding='utf-8')\n",
    "            req2 = 'SELECT text FROM `annotator_sentence` WHERE doc_id_id={}'.format(n)\n",
    "            text = ''\n",
    "            for i in db.execute(req2):\n",
    "                text += i[0]\n",
    "            texts.append(text)\n",
    "            f.write(text)\n",
    "            f.close()\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_2009 = get_original_texts('FL', 2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fl_2010 = get_original_texts('FL', 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fl_2011 = get_original_texts('FL', 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fl_2012 = get_original_texts('FL', 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hl_2009 = get_original_texts('HL', 2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hl_2010 = get_original_texts('HL', 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hl_2011 = get_original_texts('HL', 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hl_2012 = get_original_texts('HL', 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mystem = os.path.join('..', 'mystem')  # путь к mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemma(bg, year):\n",
    "    for d, dirs, files in os.walk(bg.lower() + '/' + str(year) + '/'):\n",
    "        for filename in files:\n",
    "            os.system(mystem + ' -ndl ' + os.path.join(d, filename) + ' ' + os.path.join(bg.lower(), str(year) + '_lemma', filename))\n",
    "        print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1147.txt\n",
      "1107.txt\n",
      "1187.txt\n",
      "779.txt\n",
      "2364.txt\n",
      "632.txt\n",
      "525.txt\n",
      "1506.txt\n",
      "396.txt\n",
      "1969.txt\n",
      "3170.txt\n",
      "2570.txt\n",
      "1042.txt\n",
      "1838.txt\n",
      "434.txt\n",
      "26.txt\n",
      "3213.txt\n",
      "432.txt\n",
      "110.txt\n",
      "584.txt\n",
      "1051.txt\n",
      "236.txt\n",
      "1403.txt\n",
      "312.txt\n",
      "663.txt\n",
      "1383.txt\n",
      "231.txt\n",
      "873.txt\n",
      "1530.txt\n",
      "1511.txt\n",
      "1546.txt\n",
      "3030.txt\n",
      "1759.txt\n",
      "546.txt\n",
      "1786.txt\n",
      "947.txt\n",
      "1655.txt\n",
      "3005.txt\n",
      "2830.txt\n",
      "1179.txt\n",
      "2432.txt\n",
      "2960.txt\n",
      "1936.txt\n",
      "963.txt\n",
      "564.txt\n",
      "2657.txt\n",
      "1543.txt\n",
      "1769.txt\n",
      "308.txt\n",
      "758.txt\n",
      "1699.txt\n",
      "3128.txt\n",
      "961.txt\n",
      "502.txt\n",
      "2720.txt\n",
      "727.txt\n",
      "2329.txt\n",
      "1814.txt\n",
      "258.txt\n",
      "2418.txt\n",
      "734.txt\n",
      "201.txt\n",
      "1348.txt\n",
      "313.txt\n",
      "1356.txt\n",
      "1512.txt\n",
      "1278.txt\n",
      "2924.txt\n",
      "573.txt\n",
      "253.txt\n",
      "2068.txt\n",
      "790.txt\n",
      "70.txt\n",
      "3079.txt\n",
      "1711.txt\n",
      "877.txt\n",
      "2995.txt\n",
      "1184.txt\n",
      "2955.txt\n",
      "2554.txt\n",
      "2567.txt\n",
      "76.txt\n",
      "2961.txt\n",
      "2012.txt\n",
      "3149.txt\n",
      "1983.txt\n",
      "934.txt\n",
      "2768.txt\n",
      "3016.txt\n",
      "939.txt\n",
      "387.txt\n",
      "1140.txt\n",
      "2766.txt\n",
      "1125.txt\n",
      "674.txt\n",
      "1412.txt\n",
      "114.txt\n",
      "2926.txt\n",
      "596.txt\n",
      "1060.txt\n",
      "1263.txt\n",
      "2627.txt\n",
      "1264.txt\n",
      "1427.txt\n",
      "2591.txt\n",
      "995.txt\n",
      "2250.txt\n",
      "1682.txt\n",
      "2716.txt\n",
      "944.txt\n",
      "2741.txt\n",
      "129.txt\n",
      "2651.txt\n",
      "1211.txt\n",
      "2407.txt\n",
      "565.txt\n",
      "1456.txt\n",
      "924.txt\n",
      "2186.txt\n",
      "1994.txt\n",
      "1012.txt\n",
      "2005.txt\n",
      "1772.txt\n",
      "2353.txt\n",
      "887.txt\n",
      "454.txt\n",
      "1017.txt\n",
      "1488.txt\n",
      "1662.txt\n",
      "1185.txt\n",
      "1222.txt\n",
      "2187.txt\n",
      "267.txt\n",
      "1209.txt\n",
      "1915.txt\n",
      "875.txt\n",
      "867.txt\n",
      "1224.txt\n",
      "1290.txt\n",
      "1465.txt\n",
      "3022.txt\n",
      "170.txt\n",
      "1204.txt\n",
      "1565.txt\n",
      "287.txt\n",
      "2399.txt\n",
      "3163.txt\n",
      "2264.txt\n",
      "682.txt\n",
      "1968.txt\n",
      "644.txt\n",
      "1563.txt\n",
      "333.txt\n",
      "1684.txt\n",
      "3096.txt\n",
      "132.txt\n",
      "2553.txt\n",
      "1336.txt\n",
      "2108.txt\n",
      "1226.txt\n",
      "1868.txt\n",
      "3185.txt\n",
      "2324.txt\n",
      "32.txt\n",
      "220.txt\n",
      "2153.txt\n",
      "2266.txt\n",
      "6.txt\n",
      "202.txt\n",
      "2142.txt\n",
      "1409.txt\n",
      "3202.txt\n",
      "997.txt\n",
      "2014.txt\n",
      "457.txt\n",
      "1188.txt\n",
      "2042.txt\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "lemma('FL', 2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375.txt\n",
      "3237.txt\n",
      "152.txt\n",
      "2393.txt\n",
      "243.txt\n",
      "581.txt\n",
      "1916.txt\n",
      "2317.txt\n",
      "1338.txt\n",
      "515.txt\n",
      "289.txt\n",
      "445.txt\n",
      "2774.txt\n",
      "2807.txt\n",
      "1745.txt\n",
      "3276.txt\n",
      "15.txt\n",
      "1160.txt\n",
      "1289.txt\n",
      "697.txt\n",
      "932.txt\n",
      "1568.txt\n",
      "388.txt\n",
      "2520.txt\n",
      "2948.txt\n",
      "1945.txt\n",
      "2488.txt\n",
      "906.txt\n",
      "1532.txt\n",
      "1091.txt\n",
      "748.txt\n",
      "52.txt\n",
      "1567.txt\n",
      "1932.txt\n",
      "2066.txt\n",
      "360.txt\n",
      "2937.txt\n",
      "1376.txt\n",
      "3188.txt\n",
      "1743.txt\n",
      "1513.txt\n",
      "2130.txt\n",
      "1395.txt\n",
      "1025.txt\n",
      "2885.txt\n",
      "2917.txt\n",
      "2268.txt\n",
      "690.txt\n",
      "1964.txt\n",
      "1941.txt\n",
      "795.txt\n",
      "1300.txt\n",
      "2072.txt\n",
      "1763.txt\n",
      "322.txt\n",
      "2735.txt\n",
      "420.txt\n",
      "390.txt\n",
      "504.txt\n",
      "2612.txt\n",
      "1710.txt\n",
      "994.txt\n",
      "2336.txt\n",
      "3048.txt\n",
      "326.txt\n",
      "2206.txt\n",
      "1705.txt\n",
      "3257.txt\n",
      "1366.txt\n",
      "2001.txt\n",
      "840.txt\n",
      "2084.txt\n",
      "2928.txt\n",
      "2571.txt\n",
      "2622.txt\n",
      "2356.txt\n",
      "2665.txt\n",
      "595.txt\n",
      "2215.txt\n",
      "2731.txt\n",
      "926.txt\n",
      "540.txt\n",
      "3049.txt\n",
      "44.txt\n",
      "1805.txt\n",
      "3256.txt\n",
      "1725.txt\n",
      "1285.txt\n",
      "2431.txt\n",
      "615.txt\n",
      "1984.txt\n",
      "2015.txt\n",
      "628.txt\n",
      "1367.txt\n",
      "591.txt\n",
      "714.txt\n",
      "2405.txt\n",
      "2600.txt\n",
      "1090.txt\n",
      "2979.txt\n",
      "678.txt\n",
      "904.txt\n",
      "530.txt\n",
      "2645.txt\n",
      "429.txt\n",
      "977.txt\n",
      "1847.txt\n",
      "400.txt\n",
      "3073.txt\n",
      "487.txt\n",
      "1958.txt\n",
      "692.txt\n",
      "1007.txt\n",
      "2273.txt\n",
      "2426.txt\n",
      "2381.txt\n",
      "1632.txt\n",
      "614.txt\n",
      "1637.txt\n",
      "456.txt\n",
      "2550.txt\n",
      "275.txt\n",
      "1030.txt\n",
      "805.txt\n",
      "544.txt\n",
      "956.txt\n",
      "553.txt\n",
      "1408.txt\n",
      "3119.txt\n",
      "1368.txt\n",
      "3094.txt\n",
      "411.txt\n",
      "207.txt\n",
      "2011.txt\n",
      "1825.txt\n",
      "953.txt\n",
      "2750.txt\n",
      "237.txt\n",
      "981.txt\n",
      "134.txt\n",
      "423.txt\n",
      "1660.txt\n",
      "2499.txt\n",
      "3154.txt\n",
      "1213.txt\n",
      "1317.txt\n",
      "2578.txt\n",
      "1593.txt\n",
      "832.txt\n",
      "1122.txt\n",
      "973.txt\n",
      "2145.txt\n",
      "764.txt\n",
      "1316.txt\n",
      "1269.txt\n",
      "2694.txt\n",
      "2650.txt\n",
      "1341.txt\n",
      "792.txt\n",
      "3198.txt\n",
      "2102.txt\n",
      "789.txt\n",
      "2878.txt\n",
      "2944.txt\n",
      "1098.txt\n",
      "194.txt\n",
      "1677.txt\n",
      "2099.txt\n",
      "368.txt\n",
      "616.txt\n",
      "1880.txt\n",
      "1652.txt\n",
      "1583.txt\n",
      "1320.txt\n",
      "2281.txt\n",
      "1671.txt\n",
      "48.txt\n",
      "673.txt\n",
      "3089.txt\n",
      "106.txt\n",
      "1071.txt\n",
      "1050.txt\n",
      "1726.txt\n",
      "383.txt\n",
      "2391.txt\n",
      "2680.txt\n",
      "1713.txt\n",
      "2163.txt\n",
      "415.txt\n",
      "147.txt\n",
      "3258.txt\n",
      "1630.txt\n",
      "442.txt\n",
      "2522.txt\n",
      "103.txt\n",
      "1730.txt\n",
      "2623.txt\n",
      "2189.txt\n",
      "82.txt\n",
      "2540.txt\n",
      "1515.txt\n",
      "892.txt\n",
      "2496.txt\n",
      "1913.txt\n",
      "1493.txt\n",
      "349.txt\n",
      "2870.txt\n",
      "3130.txt\n",
      "464.txt\n",
      "1791.txt\n",
      "742.txt\n",
      "2620.txt\n",
      "1696.txt\n",
      "2475.txt\n",
      "2363.txt\n",
      "770.txt\n",
      "470.txt\n",
      "2669.txt\n",
      "2483.txt\n",
      "2354.txt\n",
      "3014.txt\n",
      "821.txt\n",
      "1608.txt\n",
      "1271.txt\n",
      "1175.txt\n",
      "626.txt\n",
      "886.txt\n",
      "2166.txt\n",
      "2254.txt\n",
      "744.txt\n",
      "1248.txt\n",
      "2918.txt\n",
      "2492.txt\n",
      "1985.txt\n",
      "2791.txt\n",
      "186.txt\n",
      "3187.txt\n",
      "1438.txt\n",
      "2963.txt\n",
      "2181.txt\n",
      "3174.txt\n",
      "1993.txt\n",
      "741.txt\n",
      "1400.txt\n",
      "1818.txt\n",
      "28.txt\n",
      "2633.txt\n",
      "1393.txt\n",
      "1971.txt\n",
      "965.txt\n",
      "2888.txt\n",
      "2636.txt\n",
      "3278.txt\n",
      "1477.txt\n",
      "63.txt\n",
      "2031.txt\n",
      "447.txt\n",
      "1777.txt\n",
      "2348.txt\n",
      "1518.txt\n",
      "1903.txt\n",
      "1752.txt\n",
      "3229.txt\n",
      "1707.txt\n",
      "2436.txt\n",
      "2970.txt\n",
      "39.txt\n",
      "1665.txt\n",
      "656.txt\n",
      "53.txt\n",
      "2626.txt\n",
      "560.txt\n",
      "405.txt\n",
      "2730.txt\n",
      "1594.txt\n",
      "3192.txt\n",
      "2095.txt\n",
      "2013.txt\n",
      "214.txt\n",
      "1241.txt\n",
      "2812.txt\n",
      "351.txt\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "lemma('FL', 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "lemma('FL', 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "lemma('FL', 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "lemma('HL', 2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "lemma('HL', 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "lemma('HL', 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "lemma('HL', 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lemma_texts(bg, year):\n",
    "    lemma_texts = []\n",
    "\n",
    "    for d, dirs, files in os.walk(bg + '/' + str(year) + '_lemma/'):\n",
    "        for filename in files:\n",
    "            lemma_texts.append(open(bg + '/' + str(year) + '_lemma/' + filename, 'r', encoding='utf-8').read())  \n",
    "    \n",
    "    return lemma_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fl_2009_lemma = get_lemma_texts('fl', 2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fl_2010_lemma = get_lemma_texts('fl', 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fl_2011_lemma = get_lemma_texts('fl', 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fl_2012_lemma = get_lemma_texts('fl', 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['а',\n",
    " 'в',\n",
    " 'г',\n",
    " 'е',\n",
    " 'ж',\n",
    " 'и',\n",
    " 'к',\n",
    " 'м',\n",
    " 'о',\n",
    " 'с',\n",
    " 'т',\n",
    " 'у',\n",
    " 'я',\n",
    " 'бы',\n",
    " 'во',\n",
    " 'вы',\n",
    " 'да',\n",
    " 'до',\n",
    " 'ее',\n",
    " 'ей',\n",
    " 'ею',\n",
    " 'её',\n",
    " 'же',\n",
    " 'за',\n",
    " 'из',\n",
    " 'им',\n",
    " 'их',\n",
    " 'ли',\n",
    " 'мы',\n",
    " 'на',\n",
    " 'не',\n",
    " 'ни',\n",
    " 'но',\n",
    " 'ну',\n",
    " 'нх',\n",
    " 'об',\n",
    " 'он',\n",
    " 'от',\n",
    " 'по',\n",
    " 'со',\n",
    " 'та',\n",
    " 'те',\n",
    " 'то',\n",
    " 'ту',\n",
    " 'ты',\n",
    " 'уж',\n",
    " 'без',\n",
    " 'вам',\n",
    " 'вас',\n",
    " 'ваш',\n",
    " 'где',\n",
    " 'два',\n",
    " 'две',\n",
    " 'дел',\n",
    " 'для',\n",
    " 'его',\n",
    " 'ему',\n",
    " 'еще',\n",
    " 'ещё',\n",
    " 'или',\n",
    " 'ими',\n",
    " 'имя',\n",
    " 'как',\n",
    " 'кем',\n",
    " 'ком',\n",
    " 'кто',\n",
    " 'мне',\n",
    " 'мог',\n",
    " 'мож',\n",
    " 'мои',\n",
    " 'мой',\n",
    " 'мор',\n",
    " 'моя',\n",
    " 'моё',\n",
    " 'над',\n",
    " 'нам',\n",
    " 'нас',\n",
    " 'наш',\n",
    " 'нее',\n",
    " 'ней',\n",
    " 'нем',\n",
    " 'нет',\n",
    " 'нею',\n",
    " 'неё',\n",
    " 'них',\n",
    " 'она',\n",
    " 'они',\n",
    " 'оно',\n",
    " 'под',\n",
    " 'пор',\n",
    " 'при',\n",
    " 'про',\n",
    " 'раз',\n",
    " 'сам',\n",
    " 'сих',\n",
    " 'так',\n",
    " 'там',\n",
    " 'тем',\n",
    " 'тех',\n",
    " 'том',\n",
    " 'тот',\n",
    " 'тою',\n",
    " 'три',\n",
    " 'тут',\n",
    " 'уже',\n",
    " 'чем',\n",
    " 'что',\n",
    " 'эта',\n",
    " 'эти',\n",
    " 'это',\n",
    " 'эту',\n",
    " 'алло',\n",
    " 'бывь',\n",
    " 'вами',\n",
    " 'ваша',\n",
    " 'ваше',\n",
    " 'ваши',\n",
    " 'ведь',\n",
    " 'вниз',\n",
    " 'всем',\n",
    " 'всех',\n",
    " 'всею',\n",
    " 'года',\n",
    " 'году',\n",
    " 'даже',\n",
    " 'двух',\n",
    " 'если',\n",
    " 'есть',\n",
    " 'зато',\n",
    " 'кого',\n",
    " 'кому',\n",
    " 'куда',\n",
    " 'лишь',\n",
    " 'мало',\n",
    " 'меля',\n",
    " 'меня',\n",
    " 'мимо',\n",
    " 'мной',\n",
    " 'мною',\n",
    " 'нами',\n",
    " 'наша',\n",
    " 'наше',\n",
    " 'наши',\n",
    " 'него',\n",
    " 'нему',\n",
    " 'ниже',\n",
    " 'ними',\n",
    " 'один',\n",
    " 'пока',\n",
    " 'пора',\n",
    " 'пять',\n",
    " 'рано',\n",
    " 'семь',\n",
    " 'стал',\n",
    " 'суть',\n",
    " 'твой',\n",
    " 'твоя',\n",
    " 'твоё',\n",
    " 'тебе',\n",
    " 'тебя',\n",
    " 'теми',\n",
    " 'того',\n",
    " 'тоже',\n",
    " 'тому',\n",
    " 'туда',\n",
    " 'хоть',\n",
    " 'хотя',\n",
    " 'чаще',\n",
    " 'чего',\n",
    " 'чему',\n",
    " 'чтоб',\n",
    " 'чуть',\n",
    " 'этим',\n",
    " 'этих',\n",
    " 'этой',\n",
    " 'этом',\n",
    " 'этот',\n",
    " 'более',\n",
    " 'будто',\n",
    " 'вверх',\n",
    " 'вдали',\n",
    " 'вдруг',\n",
    " 'везде',\n",
    " 'внизу',\n",
    " 'всего',\n",
    " 'всеми',\n",
    " 'всему',\n",
    " 'всюду',\n",
    " 'давно',\n",
    " 'даром',\n",
    " 'друго',\n",
    " 'затем',\n",
    " 'зачем',\n",
    " 'здесь',\n",
    " 'какая',\n",
    " 'какой',\n",
    " 'когда',\n",
    " 'кроме',\n",
    " 'лучше',\n",
    " 'между',\n",
    " 'менее',\n",
    " 'много',\n",
    " 'можхо',\n",
    " 'назад',\n",
    " 'низко',\n",
    " 'одной',\n",
    " 'около',\n",
    " 'опять',\n",
    " 'очень',\n",
    " 'перед',\n",
    " 'позже',\n",
    " 'после',\n",
    " 'потом',\n",
    " 'почти',\n",
    " 'пятый',\n",
    " 'разве',\n",
    " 'рядом',\n",
    " 'самим',\n",
    " 'самих',\n",
    " 'самой',\n",
    " 'самом',\n",
    " 'своей',\n",
    " 'своих',\n",
    " 'сеаой',\n",
    " 'снова',\n",
    " 'собой',\n",
    " 'собою',\n",
    " 'такая',\n",
    " 'также',\n",
    " 'такие',\n",
    " 'такое',\n",
    " 'такой',\n",
    " 'тобой',\n",
    " 'тобою',\n",
    " 'тогда',\n",
    " 'тысяч',\n",
    " 'часто',\n",
    " 'через',\n",
    " 'чтобы',\n",
    " 'шесть',\n",
    " 'этими',\n",
    " 'этого',\n",
    " 'этому',\n",
    " 'близко',\n",
    " 'больше',\n",
    " 'вокруг',\n",
    " 'восемь',\n",
    " 'всегда',\n",
    " 'второй',\n",
    " 'далеко',\n",
    " 'дальше',\n",
    " 'девять',\n",
    " 'десять',\n",
    " 'другая',\n",
    " 'другие',\n",
    " 'других',\n",
    " 'другое',\n",
    " 'другой',\n",
    " 'именно',\n",
    " 'иногда',\n",
    " 'каждая',\n",
    " 'каждое',\n",
    " 'каждые',\n",
    " 'каждый',\n",
    " 'кругом',\n",
    " 'меньше',\n",
    " 'нельзя',\n",
    " 'нибудь',\n",
    " 'никуда',\n",
    " 'ничего',\n",
    " 'обычно',\n",
    " 'однако',\n",
    " 'одного',\n",
    " 'отсюда',\n",
    " 'первый',\n",
    " 'потому',\n",
    " 'почему',\n",
    " 'просто',\n",
    " 'против',\n",
    " 'раньше',\n",
    " 'самими',\n",
    " 'самого',\n",
    " 'самому',\n",
    " 'своего',\n",
    " 'сейчас',\n",
    " 'совсем',\n",
    " 'теперь',\n",
    " 'только',\n",
    " 'третий',\n",
    " 'хорошо',\n",
    " 'четыре',\n",
    " 'шестой',\n",
    " 'восьмой',\n",
    " 'впрочем',\n",
    " 'времени',\n",
    " 'девятый',\n",
    " 'десятый',\n",
    " 'конечно',\n",
    " 'которая',\n",
    " 'которой',\n",
    " 'которые',\n",
    " 'который',\n",
    " 'которых',\n",
    " 'наверху',\n",
    " 'наконец',\n",
    " 'недавно',\n",
    " 'немного',\n",
    " 'нередко',\n",
    " 'никогда',\n",
    " 'однажды',\n",
    " 'посреди',\n",
    " 'седьмой',\n",
    " 'сколько',\n",
    " 'слишком',\n",
    " 'сначала',\n",
    " 'спасибо',\n",
    " 'двадцать',\n",
    " 'довольно',\n",
    " 'которого',\n",
    " 'наиболее',\n",
    " 'недалеко',\n",
    " 'особенно',\n",
    " 'отовсюду',\n",
    " 'двадцатый',\n",
    " 'миллионов',\n",
    " 'несколько',\n",
    " 'процентов',\n",
    " 'четвертый',\n",
    " 'двенадцать',\n",
    " 'непрерывно',\n",
    " 'пожалуйста',\n",
    " 'пятнадцать',\n",
    " 'семнадцать',\n",
    " 'тринадцать',\n",
    " 'двенадцатый',\n",
    " 'одиннадцать',\n",
    " 'пятнадцатый',\n",
    " 'семнадцатый',\n",
    " 'тринадцатый',\n",
    " 'шестнадцать',\n",
    " 'восемнадцать',\n",
    " 'девятнадцать',\n",
    " 'одиннадцатый',\n",
    " 'четырнадцать',\n",
    " 'шестнадцатый',\n",
    " 'восемнадцатый',\n",
    " 'девятнадцатый',\n",
    " 'четырнадцатый']\n",
    "\n",
    "for word in ['свой', '&lt;', '«', '–', '-', '(', ')', '»', 'lt', '', \n",
    "             'из-за', 'gt', 'какой-то', 'д', 'name', 'ого', 'ом']:\n",
    "    stop_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freq_stop(fname, meta, texts):\n",
    "    dic = {}\n",
    "    number = 0 # сколько всего слов\n",
    "    \n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        for indx, word in enumerate(words):\n",
    "            number += 1\n",
    "            word = word.lower()\n",
    "            words[indx] = word.strip('.,!@?#$%^&*():\"№;%=-,')\n",
    "            if words[indx] not in stop_words:\n",
    "                if words[indx] not in dic:\n",
    "                    dic[words[indx]] = 1\n",
    "                else:\n",
    "                    dic[words[indx]] += 1\n",
    "                    \n",
    "    f = open('stats/' + fname, 'w', encoding='utf-8')\n",
    "    f.write(meta + '\\n')\n",
    "\n",
    "    i = 0\n",
    "    for w in sorted(dic, key=dic.get, reverse=True):\n",
    "        if i < 100:\n",
    "            f.write(w + ' ' + str(dic[w]) + ' ' + str(round(dic[w] / number * 1000000, 2)) + '\\n')\n",
    "        else:\n",
    "            break\n",
    "        i += 1\n",
    "    print(number)\n",
    "        \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30837\n"
     ]
    }
   ],
   "source": [
    "freq_stop('fl_2009_lemma.txt', 'L2 speakers, year 2009, frequent lemmas', fl_2009_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56585\n"
     ]
    }
   ],
   "source": [
    "freq_stop('fl_2010_lemma.txt', 'L2 speakers, year 2010, frequent lemmas', fl_2010_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75356\n"
     ]
    }
   ],
   "source": [
    "freq_stop('fl_2011_lemma.txt', 'L2 speakers, year 2011, frequent lemmas', fl_2011_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93849\n"
     ]
    }
   ],
   "source": [
    "freq_stop('fl_2012_lemma.txt', 'L2 speakers, year 2012, frequent lemmas', fl_2012_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hl_2009_lemma = get_lemma_texts('hl', 2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hl_2010_lemma = get_lemma_texts('hl', 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hl_2011_lemma = get_lemma_texts('hl', 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hl_2012_lemma = get_lemma_texts('hl', 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90971\n"
     ]
    }
   ],
   "source": [
    "freq_stop('hl_2009_lemma.txt', 'Heritage speakers, year 2009, frequent lemmas', hl_2009_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49061\n"
     ]
    }
   ],
   "source": [
    "freq_stop('hl_2010_lemma.txt', 'Heritage speakers, year 2010, frequent lemmas', hl_2010_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34531\n"
     ]
    }
   ],
   "source": [
    "freq_stop('hl_2011_lemma.txt', 'Heritage speakers, year 2011, frequent lemmas', hl_2011_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39798\n"
     ]
    }
   ],
   "source": [
    "freq_stop('hl_2012_lemma.txt', 'Heritage speakers, year 2012, frequent lemmas', hl_2012_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_common(bg):\n",
    "    lem_09 = open('stats/' + bg + '_2009_lemma.txt', 'r', encoding='utf-8').readlines()\n",
    "    lem_10 = open('stats/' + bg + '_2010_lemma.txt', 'r', encoding='utf-8').readlines()\n",
    "    lem_11 = open('stats/' + bg + '_2011_lemma.txt', 'r', encoding='utf-8').readlines()\n",
    "    lem_12 = open('stats/' + bg + '_2012_lemma.txt', 'r', encoding='utf-8').readlines()\n",
    "    \n",
    "    del lem_09[0]\n",
    "    del lem_10[0]\n",
    "    del lem_11[0]\n",
    "    del lem_12[0]\n",
    "    \n",
    "    dict_09 = dict()\n",
    "    dict_10 = dict()\n",
    "    dict_11 = dict()\n",
    "    dict_12 = dict()\n",
    "    \n",
    "    for indx, el in enumerate(lem_09):\n",
    "        dict_09[el.split(' ')[0]] = el.split(' ')[1:]\n",
    "    for indx, el in enumerate(lem_10):\n",
    "        dict_10[el.split(' ')[0]] = el.split(' ')[1:]\n",
    "    for indx, el in enumerate(lem_11):\n",
    "        dict_11[el.split(' ')[0]] = el.split(' ')[1:]\n",
    "    for indx, el in enumerate(lem_12):\n",
    "        dict_12[el.split(' ')[0]] = el.split(' ')[1:]\n",
    "        \n",
    "    common = set(dict_09.keys()) & set(dict_10.keys()) & set(dict_11.keys()) & set(dict_12.keys())\n",
    "    \n",
    "    fw = open('stats/' + bg + '_common.txt', 'w', encoding='utf-8')\n",
    "    for c in common:\n",
    "        fw.write(c + '\\n')\n",
    "        fw.write(dict_09[c][0] + ' ' + dict_09[c][1])\n",
    "        fw.write(dict_10[c][0] + ' ' + dict_10[c][1])\n",
    "        fw.write(dict_11[c][0] + ' ' + dict_11[c][1])\n",
    "        fw.write(dict_12[c][0] + ' ' + dict_12[c][1])\n",
    "        fw.write('\\n')   \n",
    "        \n",
    "    print(len(common))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "get_common('fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "get_common('hl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lexicalrichness import LexicalRichness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexical_diversity(texts):\n",
    "\n",
    "    lemmed = []\n",
    "\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        lemmed += words\n",
    "    \n",
    "    lex = LexicalRichness(' '.join(lemmed))\n",
    "        \n",
    "    print('TTR: ', str(lex.ttr))\n",
    "    print('MTLD: ', str(lex.mtld(threshold=0.72)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTR:  0.11511771191387249\n",
      "MTLD:  89.44873582171937\n"
     ]
    }
   ],
   "source": [
    "lexical_diversity(fl_2009_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTR:  0.11552531589643898\n",
      "MTLD:  93.37838463248991\n"
     ]
    }
   ],
   "source": [
    "lexical_diversity(fl_2010_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTR:  0.09161723529333705\n",
      "MTLD:  95.28324389647383\n"
     ]
    }
   ],
   "source": [
    "lexical_diversity(fl_2011_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTR:  0.07826318593500266\n",
      "MTLD:  96.13224633260991\n"
     ]
    }
   ],
   "source": [
    "lexical_diversity(fl_2012_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTR:  0.07951809877656008\n",
      "MTLD:  116.74225502323321\n"
     ]
    }
   ],
   "source": [
    "lexical_diversity(hl_2009_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTR:  0.12280129629252186\n",
      "MTLD:  111.71422848629533\n"
     ]
    }
   ],
   "source": [
    "lexical_diversity(hl_2010_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTR:  0.1386829607320746\n",
      "MTLD:  106.6758381833841\n"
     ]
    }
   ],
   "source": [
    "lexical_diversity(hl_2011_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTR:  0.12337303382079501\n",
      "MTLD:  107.32745243953417\n"
     ]
    }
   ],
   "source": [
    "lexical_diversity(hl_2012_lemma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
